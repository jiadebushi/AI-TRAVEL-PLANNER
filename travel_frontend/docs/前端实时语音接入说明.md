# 前端接入实时语音识别（科大讯飞 IAT）

本文档说明前端如何通过 WebSocket 调用后端实时语音识别接口，并在输入框中实时显示识别结果。

## 后端接口

- 协议: WebSocket
- 地址: `ws://<your-host>/api/v1/voice/realtime`
- 行为:
  - 前端发送二进制音频块（建议 16kHz / 16bit / 单声道 PCM/L16）
  - 后端转发至科大讯飞实时识别服务
  - 后端将识别文本以文本消息（string）实时推送给前端
  - 发送文本 `"stop"` 或关闭连接即可结束会话

## 前端实现思路

1) 申请麦克风权限并采集音频
2) 将音频转换为 16kHz/16bit/Mono 的 PCM 二进制块
3) 建立 WebSocket 连接，持续发送音频块
4) 接收文本消息，实时显示到输入框

> 注：Chrome/Edge 可使用 WebAudio API 重采样并导出 PCM；Safari 可能需要前端编码策略调整。

## 示例代码（WebAudio + WebSocket）

```html
<input id="asrInput" type="text" placeholder="语音识别文本会显示在这里" style="width: 100%" />
<button id="startBtn">开始识别</button>
<button id="stopBtn">停止</button>
<script>
  const WS_URL = `ws://${location.host}/api/v1/voice/realtime`;

  let ws;
  let audioContext;
  let mediaStream;
  let processor;

  const $input = document.getElementById('asrInput');
  const $start = document.getElementById('startBtn');
  const $stop = document.getElementById('stopBtn');

  $start.onclick = async () => {
    try {
      // 1) 打开WebSocket
      ws = new WebSocket(WS_URL);
      ws.binaryType = 'arraybuffer';
      ws.onmessage = (evt) => {
        const text = evt.data; // 后端推送的识别文本（string）
        if (typeof text === 'string') {
          // 简单拼接显示（可根据需要做更复杂的增量合并）
          $input.value = text;
        }
      };

      ws.onopen = async () => {
        // 2) 采集麦克风
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(mediaStream);

        // 3) 使用 ScriptProcessorNode 获取 PCM 数据（16k/mono）
        const bufferSize = 4096;
        processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
        processor.onaudioprocess = (e) => {
          const input = e.inputBuffer.getChannelData(0); // Float32 [-1,1]
          // 转 Int16 PCM
          const pcm16 = floatTo16BitPCM(input);
          if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send(pcm16.buffer); // 发送二进制音频块
          }
        };
        source.connect(processor);
        processor.connect(audioContext.destination);
      };

      ws.onerror = (e) => console.error('WS error', e);
      ws.onclose = () => console.log('WS closed');
    } catch (err) {
      console.error(err);
      alert('启动识别失败：' + err.message);
    }
  };

  $stop.onclick = async () => {
    try {
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send('stop');
        ws.close();
      }
      if (processor) {
        processor.disconnect();
        processor = null;
      }
      if (audioContext) {
        await audioContext.close();
        audioContext = null;
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach((t) => t.stop());
        mediaStream = null;
      }
    } catch {}
  };

  function floatTo16BitPCM(float32Array) {
    const len = float32Array.length;
    const buffer = new ArrayBuffer(len * 2);
    const view = new DataView(buffer);
    let offset = 0;
    for (let i = 0; i < len; i++, offset += 2) {
      let s = Math.max(-1, Math.min(1, float32Array[i]));
      // 转为Int16
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
    }
    return new Uint8Array(buffer);
  }
</script>
```

## 常见问题（FAQ）

- Q: 识别延迟较高？
  - 建议减小 bufferSize（如 2048/1024）以更频繁地发送小块音频；注意 CPU 负载。
- Q: 出现“音频格式不正确”？
  - 确保发送的是 16kHz、单声道、16bit PCM 数据。若原始设备采样率非 16k，可依赖 AudioContext({ sampleRate: 16000 }) 或自定义重采样。
- Q: Safari 兼容性？
  - 需使用 `webkitAudioContext`，并确保用户手势触发音频播放/录音；部分版本对 ScriptProcessorNode 支持较弱，可改用 AudioWorklet。
- Q: 断开与结束？
  - 发送文本 `stop` 或直接关闭 WebSocket；后端会发送结束帧并关闭到科大讯飞的连接。

## 与后端约定

- WebSocket 文本消息：识别文本（增量）
- WebSocket 二进制消息：音频 PCM 数据块
- 会话结束：前端发 `stop` 或直接关闭连接

---

如需将识别结果与业务表单合并、支持多语言或更完整的增量拼接逻辑，可在收到的文本消息上做细粒度的缓存与合并策略。


